{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "responsible-optics",
   "metadata": {},
   "source": [
    "# Experiments and Demonstration Record of Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "sharing-elements",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import EfficientNetB0, EfficientNetB2, EfficientNetB4, EfficientNetB7\n",
    "from tensorflow.keras.layers import Concatenate, Dense, Dropout, Flatten, GlobalAveragePooling2D, Input, LSTM, TimeDistributed\n",
    "from tensorflow.keras import Model\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "literary-hughes",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "mental-jewel",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.img_seq_generator import ImageSequenceDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "three-class",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "# tf.config.set_logical_device_configuration(physical_devices[0], [tf.config.LogicalDeviceConfiguration(memory_limit=4096)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "loaded-jamaica",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_PATH = Path(r'D:\\Uni\\Honours\\Project\\data\\autsl\\outputs\\runs')\n",
    "INPUT_TRAIN = Path(r'D:\\Uni\\Honours\\Project\\data\\autsl\\frames_rgb_20\\train')\n",
    "INPUT_VAL = Path(r'D:\\Uni\\Honours\\Project\\data\\autsl\\frames_rgb_20\\val')\n",
    "INPUT_TEST = Path(r'D:\\Uni\\Honours\\Project\\data\\autsl\\frames_rgb_20\\test')\n",
    "INPUT_TRAIN_DEPTH = Path(r'D:\\Uni\\Honours\\Project\\data\\autsl\\frames_depth_20\\train')\n",
    "INPUT_VAL_DEPTH = Path(r'D:\\Uni\\Honours\\Project\\data\\autsl\\frames_depth_20\\val')\n",
    "INPUT_TEST_DEPTH = Path(r'D:\\Uni\\Honours\\Project\\data\\autsl\\frames_depth_20\\test')\n",
    "\n",
    "TRAIN_LABEL_PATH = Path(r'D:\\Uni\\Honours\\Project\\data\\autsl\\train_labels_20classes.csv')\n",
    "VAL_LABEL_PATH = Path(r'D:\\Uni\\Honours\\Project\\data\\autsl\\val_labels_20classes.csv')\n",
    "TEST_LABEL_PATH = Path(r'D:\\Uni\\Honours\\Project\\data\\autsl\\test_labels_20classes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "prepared-click",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(TRAIN_LABEL_PATH)\n",
    "val_df = pd.read_csv(VAL_LABEL_PATH)\n",
    "test_df = pd.read_csv(TEST_LABEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "conscious-store",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SHAPE=(224,224,3)\n",
    "TIME_DIST_SHAPE=(None,224,224,3)\n",
    "NUM_CLASSES = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "romance-heater",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = ImageSequenceDataGenerator(train_df, INPUT_TRAIN, batch_size=8, input_size=INPUT_SHAPE, shuffle=True)\n",
    "val_generator = ImageSequenceDataGenerator(val_df, INPUT_VAL, batch_size=8, input_size=INPUT_SHAPE, shuffle=False)\n",
    "# test_generator = ImageSequenceDataGenerator(test_df, INPUT_TEST, batch_size=8, input_size=INPUT_SHAPE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "baking-version",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_depth_generator = ImageSequenceDataGenerator(train_df, INPUT_TRAIN_DEPTH, batch_size=8, input_size=INPUT_SHAPE, shuffle=True)\n",
    "val_depth_generator = ImageSequenceDataGenerator(val_df, INPUT_VAL_DEPTH, batch_size=8, input_size=INPUT_SHAPE, shuffle=False)\n",
    "# test_depth_generator = ImageSequenceDataGenerator(test_df, INPUT_TEST_DEPTH, batch_size=8, input_size=INPUT_SHAPE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "orange-player",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_train_generator():\n",
    "    for i in range(len(train_generator)):\n",
    "        yield train_generator.getitem(i)\n",
    "        \n",
    "def gen_val_generator():\n",
    "    for i in range(len(val_generator)):\n",
    "        yield val_generator.getitem(i)\n",
    "        \n",
    "train_dataset = tf.data.Dataset.from_generator(\n",
    "    gen_train_generator, \n",
    "    output_signature=(\n",
    "        tf.TensorSpec(shape=(None, *TIME_DIST_SHAPE), dtype=tf.float32),\n",
    "        tf.TensorSpec(shape=(None, 20), dtype=tf.float32)\n",
    "    )\n",
    ")\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_generator(\n",
    "    gen_val_generator, \n",
    "    output_signature=(\n",
    "        tf.TensorSpec(shape=(None, *TIME_DIST_SHAPE), dtype=tf.float32),\n",
    "        tf.TensorSpec(shape=(None, 20), dtype=tf.float32)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "personal-peeing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_train_depth_generator():\n",
    "    for i in range(len(train_depth_generator)):\n",
    "        yield train_depth_generator.getitem(i)\n",
    "        \n",
    "def gen_val_depth_generator():\n",
    "    for i in range(len(val_depth_generator)):\n",
    "        yield val_generator.getitem(i)\n",
    "        \n",
    "train_depth_dataset = tf.data.Dataset.from_generator(\n",
    "    gen_train_depth_generator, \n",
    "    output_signature=(\n",
    "        tf.TensorSpec(shape=(None, *TIME_DIST_SHAPE), dtype=tf.float32),\n",
    "        tf.TensorSpec(shape=(None, 20), dtype=tf.float32)\n",
    "    )\n",
    ")\n",
    "\n",
    "val_depth_dataset = tf.data.Dataset.from_generator(\n",
    "    gen_val_depth_generator, \n",
    "    output_signature=(\n",
    "        tf.TensorSpec(shape=(None, *TIME_DIST_SHAPE), dtype=tf.float32),\n",
    "        tf.TensorSpec(shape=(None, 20), dtype=tf.float32)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confused-depth",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator Test\n",
    "# Note that Y is ordered alphabetically and one hot encoded\n",
    "train_batch0 = train_generator[0]\n",
    "print(\"X: \", train_batch0[0][0])\n",
    "print(\"Y: \", train_batch0[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entitled-cleaning",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator Test\n",
    "# Note that Y is ordered alphabetically and one hot encoded\n",
    "val_batch0 = val_generator[0]\n",
    "print(\"X: \", val_batch0[0][0])\n",
    "print(\"Y: \", val_batch0[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "returning-button",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator Test\n",
    "# Note that Y is ordered alphabetically and one hot encoded\n",
    "test_batch0 = test_generator[0]\n",
    "print(\"X: \", test_batch0[0][0])\n",
    "print(\"Y: \", test_batch0[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boring-reliance",
   "metadata": {},
   "source": [
    "## EfficientNetB0\n",
    "https://www.tensorflow.org/api_docs/python/tf/keras/applications/efficientnet/EfficientNetB0\n",
    "\n",
    "Using transfer learning, we test training with EfficientNetB0 and our custom data generator based on dataframes.\n",
    "\n",
    "EfficientNetB0 is lightweight, and would be similar to mobile deployed platforms and can be considered an equivalent test for lightweight models based on parameter size.\n",
    "\n",
    "EfficientNetB0 has 5,330,571 parameters, and a 29MB model size.\n",
    "MobileNetV2 has 3,538,984 parameters, and a 14MB model size.\n",
    "NasNetMobile has 5,326,716 parameters, and a 23MB model size.\n",
    "\n",
    "Furthermore EfficientNetB0 scored 77.1% Top-1 Accuracy and 93.3% Top-5 Accuracy on imagenet beating ResNet50 (76.0%, 93.0%) whilst being 5x smaller.\n",
    "\n",
    "See: https://arxiv.org/pdf/1905.11946.pdf\n",
    "\n",
    "Therefore, I use EfficientNetB0 has the baseline transfer learning model. Other models to be used are B2 (9.2M parameters) B4 (19m parameters), and B7 (66m parameters) to gauge different sized models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "generous-marks",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_efficientnet(model_num=0, input_size=(224,224,3), finetune=False, tune_layers=3):\n",
    "    model = None\n",
    "    if model_num == 0:\n",
    "        model = EfficientNetB0(include_top=False, weights='imagenet', input_shape=input_size)\n",
    "    elif model_num == 2:\n",
    "        model = EfficientNetB2(include_top=False, weights='imagenet', input_shape=input_size)\n",
    "    elif model_num == 4:\n",
    "        model = EfficientNetB4(include_top=False, weights='imagenet', input_shape=input_size)\n",
    "    elif model_num == 7:\n",
    "        model = EfficientNetB7(include_top=False, weights='imagenet', input_shape=input_size)\n",
    "    else:\n",
    "        print(\"Model not found, ensure model number is in range [0, 7].\")\n",
    "    \n",
    "    if not finetune:\n",
    "        model.trainable = False\n",
    "    else:\n",
    "        for layer in model.layers[:-tune_layers]:\n",
    "            layer.trainable = False\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "civilian-commons",
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_feature_model(num_classes, model_num=0, input_shape=(224,224,3), time_dist_shape=(None,224,224,3), dropout=0.5, dense_n=128, lstm_n=256, finetune=False, tune_layers=3):\n",
    "    efficient_net = get_efficientnet(model_num=0, input_size=input_shape, finetune=finetune, tune_layers=tune_layers)\n",
    "    \n",
    "    # Transfer Layers\n",
    "    input_tensor = Input(shape=time_dist_shape)\n",
    "    efficient_layer = TimeDistributed(efficient_net, name=f\"EfficientNetB{model_num}\")(input_tensor)\n",
    "    # Use pooling layer to reduce number of parameters by 12x\n",
    "    efficient_out = TimeDistributed(GlobalAveragePooling2D())(efficient_layer)\n",
    "#     efficient_out = TimeDistributed(Flatten())(efficient_layer)\n",
    "    \n",
    "    # LSTM Sequence Layer\n",
    "    lstm = LSTM(lstm_n)(efficient_out)\n",
    "    fc = Dense(dense_n, activation='relu')(lstm)\n",
    "    fc_out = Dropout(dropout)(fc) \n",
    "    output = Dense(num_classes, activation='softmax')(fc_out)\n",
    "    \n",
    "    # Compile with Adam\n",
    "    model = Model(input_tensor, output)\n",
    "    model.compile('adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "irish-peoples",
   "metadata": {},
   "outputs": [],
   "source": [
    "# early_stop_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "# csv_callback = tf.keras.callbacks.CSVLogger('training.log')\n",
    "\n",
    "def set_csv_callback(output_path, name: str):\n",
    "    csv_path = Path(output_path, name)\n",
    "    return tf.keras.callbacks.CSVLogger(csv_path)\n",
    "\n",
    "def set_early_stop_callback(patience, monitor='val_loss'):\n",
    "    return tf.keras.callbacks.EarlyStopping(monitor=monitor, patience=patience)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sapphire-restriction",
   "metadata": {},
   "source": [
    "# RGB Only"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "earlier-reunion",
   "metadata": {},
   "source": [
    "## EfficientNetB0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bearing-cabin",
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb_model = single_feature_model(20, model_num=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "detected-serbia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, None, 224, 224, 3 0         \n",
      "_________________________________________________________________\n",
      "EfficientNetB0 (TimeDistribu (None, None, 7, 7, 1280)  4049571   \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, None, 1280)        0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 256)               1573888   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 20)                2580      \n",
      "=================================================================\n",
      "Total params: 5,658,935\n",
      "Trainable params: 1,609,364\n",
      "Non-trainable params: 4,049,571\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "rgb_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "electronic-pennsylvania",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_log = 'training_rgb_001.log'\n",
    "run_model_summary = 'training_rgb_001_model_summary.txt'\n",
    "model_checkpoint = 'training_rgb_001.best.hdf5'\n",
    "\n",
    "with open(Path(OUTPUT_PATH, run_model_summary), 'w') as f:\n",
    "    rgb_model.summary(print_fn=lambda x: f.write(x + '\\n'))\n",
    "\n",
    "early_stop_callback = set_early_stop_callback(5)\n",
    "csv_callback = set_csv_callback(OUTPUT_PATH, run_log)\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath=Path(OUTPUT_PATH, model_checkpoint), \n",
    "                                                monitor='val_loss',\n",
    "                                                verbose=0,\n",
    "                                                save_best_only=True,\n",
    "                                                mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "wooden-impossible",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "307/307 [==============================] - 340s 1s/step - loss: 3.0044 - accuracy: 0.0650 - val_loss: 2.9039 - val_accuracy: 0.0969\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.90392, saving model to D:\\Uni\\Honours\\Project\\data\\autsl\\outputs\\runs\\training_rgb_001.best.hdf5\n",
      "Epoch 2/100\n",
      "307/307 [==============================] - 304s 991ms/step - loss: 2.9180 - accuracy: 0.0775 - val_loss: 2.9015 - val_accuracy: 0.0689\n",
      "\n",
      "Epoch 00002: val_loss improved from 2.90392 to 2.90149, saving model to D:\\Uni\\Honours\\Project\\data\\autsl\\outputs\\runs\\training_rgb_001.best.hdf5\n",
      "Epoch 3/100\n",
      "307/307 [==============================] - 301s 982ms/step - loss: 2.8993 - accuracy: 0.0804 - val_loss: 2.8742 - val_accuracy: 0.1020\n",
      "\n",
      "Epoch 00003: val_loss improved from 2.90149 to 2.87422, saving model to D:\\Uni\\Honours\\Project\\data\\autsl\\outputs\\runs\\training_rgb_001.best.hdf5\n",
      "Epoch 4/100\n",
      "307/307 [==============================] - 300s 976ms/step - loss: 2.8210 - accuracy: 0.1205 - val_loss: 2.7205 - val_accuracy: 0.1327\n",
      "\n",
      "Epoch 00004: val_loss improved from 2.87422 to 2.72047, saving model to D:\\Uni\\Honours\\Project\\data\\autsl\\outputs\\runs\\training_rgb_001.best.hdf5\n",
      "Epoch 5/100\n",
      "307/307 [==============================] - 883s 3s/step - loss: 2.5815 - accuracy: 0.1494 - val_loss: 2.7705 - val_accuracy: 0.1352\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 2.72047\n",
      "Epoch 6/100\n",
      "307/307 [==============================] - 1168s 4s/step - loss: 2.4160 - accuracy: 0.1742 - val_loss: 2.5597 - val_accuracy: 0.1709\n",
      "\n",
      "Epoch 00006: val_loss improved from 2.72047 to 2.55974, saving model to D:\\Uni\\Honours\\Project\\data\\autsl\\outputs\\runs\\training_rgb_001.best.hdf5\n",
      "Epoch 7/100\n",
      "307/307 [==============================] - 961s 3s/step - loss: 2.2472 - accuracy: 0.2025 - val_loss: 2.4822 - val_accuracy: 0.1913\n",
      "\n",
      "Epoch 00007: val_loss improved from 2.55974 to 2.48221, saving model to D:\\Uni\\Honours\\Project\\data\\autsl\\outputs\\runs\\training_rgb_001.best.hdf5\n",
      "Epoch 8/100\n",
      "307/307 [==============================] - 714s 2s/step - loss: 2.1269 - accuracy: 0.2235 - val_loss: 2.4848 - val_accuracy: 0.1735\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 2.48221\n",
      "Epoch 9/100\n",
      "307/307 [==============================] - 497s 2s/step - loss: 2.0393 - accuracy: 0.2290 - val_loss: 2.4382 - val_accuracy: 0.1760\n",
      "\n",
      "Epoch 00009: val_loss improved from 2.48221 to 2.43815, saving model to D:\\Uni\\Honours\\Project\\data\\autsl\\outputs\\runs\\training_rgb_001.best.hdf5\n",
      "Epoch 10/100\n",
      "307/307 [==============================] - 437s 1s/step - loss: 1.9428 - accuracy: 0.2972 - val_loss: 2.4273 - val_accuracy: 0.1760\n",
      "\n",
      "Epoch 00010: val_loss improved from 2.43815 to 2.42732, saving model to D:\\Uni\\Honours\\Project\\data\\autsl\\outputs\\runs\\training_rgb_001.best.hdf5\n",
      "Epoch 11/100\n",
      "307/307 [==============================] - 341s 1s/step - loss: 1.8724 - accuracy: 0.3118 - val_loss: 2.3326 - val_accuracy: 0.1939\n",
      "\n",
      "Epoch 00011: val_loss improved from 2.42732 to 2.33263, saving model to D:\\Uni\\Honours\\Project\\data\\autsl\\outputs\\runs\\training_rgb_001.best.hdf5\n",
      "Epoch 12/100\n",
      "307/307 [==============================] - 336s 1s/step - loss: 1.7454 - accuracy: 0.3590 - val_loss: 2.3596 - val_accuracy: 0.2117\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 2.33263\n",
      "Epoch 13/100\n",
      "307/307 [==============================] - 335s 1s/step - loss: 1.6848 - accuracy: 0.3773 - val_loss: 2.4889 - val_accuracy: 0.2117\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 2.33263\n",
      "Epoch 14/100\n",
      "307/307 [==============================] - 336s 1s/step - loss: 1.6564 - accuracy: 0.3780 - val_loss: 2.7528 - val_accuracy: 0.1760\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 2.33263\n",
      "Epoch 15/100\n",
      "307/307 [==============================] - 323s 1s/step - loss: 1.5755 - accuracy: 0.4004 - val_loss: 2.6408 - val_accuracy: 0.2270\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 2.33263\n",
      "Epoch 16/100\n",
      "307/307 [==============================] - 305s 993ms/step - loss: 1.4923 - accuracy: 0.4237 - val_loss: 2.4547 - val_accuracy: 0.2296\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 2.33263\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "rgb_train_history = rgb_model.fit(\n",
    "    x=train_dataset, \n",
    "    validation_data=val_dataset, \n",
    "    epochs=100, \n",
    "    callbacks=[early_stop_callback, csv_callback, checkpoint], \n",
    "    workers=5, \n",
    "    use_multiprocessing=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "active-harris",
   "metadata": {},
   "source": [
    "## EfficientNetB2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "entertaining-publicity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, None, 224, 224, 3 0         \n",
      "_________________________________________________________________\n",
      "EfficientNetB2 (TimeDistribu (None, None, 7, 7, 1280)  4049571   \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, None, 1280)        0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 256)               1573888   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 20)                2580      \n",
      "=================================================================\n",
      "Total params: 5,658,935\n",
      "Trainable params: 1,609,364\n",
      "Non-trainable params: 4,049,571\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "rgb_model = single_feature_model(20, model_num=2)\n",
    "rgb_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "general-upper",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_log = 'training_rgb_002.log'\n",
    "run_model_summary = 'training_rgb_002_model_summary.txt'\n",
    "model_checkpoint = 'training_rgb_002.best.hdf5'\n",
    "\n",
    "with open(Path(OUTPUT_PATH, run_model_summary), 'w') as f:\n",
    "    rgb_model.summary(print_fn=lambda x: f.write(x + '\\n'))\n",
    "\n",
    "early_stop_callback = set_early_stop_callback(5)\n",
    "csv_callback = set_csv_callback(OUTPUT_PATH, run_log)\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath=Path(OUTPUT_PATH, model_checkpoint), \n",
    "                                                monitor='val_loss',\n",
    "                                                verbose=0,\n",
    "                                                save_best_only=True,\n",
    "                                                mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "gross-second",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "307/307 [==============================] - 338s 1s/step - loss: 3.0098 - accuracy: 0.0770 - val_loss: 2.9129 - val_accuracy: 0.0867\n",
      "Epoch 2/100\n",
      "307/307 [==============================] - 316s 1s/step - loss: 2.9236 - accuracy: 0.1005 - val_loss: 2.8945 - val_accuracy: 0.0765\n",
      "Epoch 3/100\n",
      "307/307 [==============================] - 308s 1s/step - loss: 2.9074 - accuracy: 0.0863 - val_loss: 2.8724 - val_accuracy: 0.0816\n",
      "Epoch 4/100\n",
      "307/307 [==============================] - 318s 1s/step - loss: 2.8443 - accuracy: 0.0856 - val_loss: 2.7875 - val_accuracy: 0.1224\n",
      "Epoch 5/100\n",
      "307/307 [==============================] - 317s 1s/step - loss: 2.6833 - accuracy: 0.1352 - val_loss: 2.6702 - val_accuracy: 0.1531\n",
      "Epoch 6/100\n",
      "307/307 [==============================] - 307s 1s/step - loss: 2.4648 - accuracy: 0.1843 - val_loss: 2.5081 - val_accuracy: 0.1709\n",
      "Epoch 7/100\n",
      "307/307 [==============================] - 308s 1s/step - loss: 2.2574 - accuracy: 0.2224 - val_loss: 2.4625 - val_accuracy: 0.1990\n",
      "Epoch 8/100\n",
      "307/307 [==============================] - 1352s 4s/step - loss: 2.1143 - accuracy: 0.2330 - val_loss: 2.4576 - val_accuracy: 0.1888\n",
      "Epoch 9/100\n",
      "307/307 [==============================] - 1282s 4s/step - loss: 2.0375 - accuracy: 0.2624 - val_loss: 2.3323 - val_accuracy: 0.2526\n",
      "Epoch 10/100\n",
      "307/307 [==============================] - 1143s 4s/step - loss: 1.9105 - accuracy: 0.3069 - val_loss: 2.1860 - val_accuracy: 0.2908\n",
      "Epoch 11/100\n",
      "307/307 [==============================] - 1138s 4s/step - loss: 1.8058 - accuracy: 0.3415 - val_loss: 2.1318 - val_accuracy: 0.2551\n",
      "Epoch 12/100\n",
      "307/307 [==============================] - 1161s 4s/step - loss: 1.6537 - accuracy: 0.3966 - val_loss: 2.1638 - val_accuracy: 0.3061\n",
      "Epoch 13/100\n",
      "307/307 [==============================] - 578s 2s/step - loss: 1.5912 - accuracy: 0.4028 - val_loss: 2.2382 - val_accuracy: 0.3010\n",
      "Epoch 14/100\n",
      "307/307 [==============================] - 472s 2s/step - loss: 1.5053 - accuracy: 0.4281 - val_loss: 2.6044 - val_accuracy: 0.2474\n",
      "Epoch 15/100\n",
      "307/307 [==============================] - 473s 2s/step - loss: 1.4601 - accuracy: 0.4559 - val_loss: 2.3740 - val_accuracy: 0.2857\n",
      "Epoch 16/100\n",
      "307/307 [==============================] - 425s 1s/step - loss: 1.3514 - accuracy: 0.4964 - val_loss: 2.3517 - val_accuracy: 0.3240\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "rgb_train_history = rgb_model.fit(\n",
    "    x=train_dataset, \n",
    "    validation_data=val_dataset, \n",
    "    epochs=100, \n",
    "    callbacks=[early_stop_callback, csv_callback, checkpoint], \n",
    "    workers=5, \n",
    "    use_multiprocessing=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "little-rabbit",
   "metadata": {},
   "source": [
    "## EfficientNetB4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "abandoned-offense",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, None, 224, 224, 3 0         \n",
      "_________________________________________________________________\n",
      "EfficientNetB4 (TimeDistribu (None, None, 7, 7, 1280)  4049571   \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, None, 1280)        0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 256)               1573888   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 20)                2580      \n",
      "=================================================================\n",
      "Total params: 5,658,935\n",
      "Trainable params: 1,609,364\n",
      "Non-trainable params: 4,049,571\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "rgb_model = single_feature_model(20, model_num=4)\n",
    "rgb_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "likely-dividend",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_log = 'training_rgb_003.csv'\n",
    "run_model_summary = 'training_rgb_003_model_summary.txt'\n",
    "model_checkpoint = 'training_rgb_003.best.hdf5'\n",
    "\n",
    "with open(Path(OUTPUT_PATH, run_model_summary), 'w') as f:\n",
    "    rgb_model.summary(print_fn=lambda x: f.write(x + '\\n'))\n",
    "\n",
    "early_stop_callback = set_early_stop_callback(5)\n",
    "csv_callback = set_csv_callback(OUTPUT_PATH, run_log)\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath=Path(OUTPUT_PATH, model_checkpoint), \n",
    "                                                monitor='val_loss',\n",
    "                                                verbose=0,\n",
    "                                                save_best_only=True,\n",
    "                                                mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "secret-profile",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "307/307 [==============================] - 482s 2s/step - loss: 3.0219 - accuracy: 0.0688 - val_loss: 2.9300 - val_accuracy: 0.0791\n",
      "Epoch 2/100\n",
      "307/307 [==============================] - 301s 980ms/step - loss: 2.9701 - accuracy: 0.0726 - val_loss: 2.9170 - val_accuracy: 0.0714\n",
      "Epoch 3/100\n",
      "307/307 [==============================] - 300s 978ms/step - loss: 2.9455 - accuracy: 0.0725 - val_loss: 2.8932 - val_accuracy: 0.0842\n",
      "Epoch 4/100\n",
      "307/307 [==============================] - 300s 979ms/step - loss: 2.9112 - accuracy: 0.0799 - val_loss: 2.8667 - val_accuracy: 0.0867\n",
      "Epoch 5/100\n",
      "307/307 [==============================] - 300s 979ms/step - loss: 2.8223 - accuracy: 0.1002 - val_loss: 2.7662 - val_accuracy: 0.1097\n",
      "Epoch 6/100\n",
      "307/307 [==============================] - 300s 976ms/step - loss: 2.7099 - accuracy: 0.1126 - val_loss: 2.6568 - val_accuracy: 0.1378\n",
      "Epoch 7/100\n",
      "307/307 [==============================] - 299s 975ms/step - loss: 2.5711 - accuracy: 0.1438 - val_loss: 2.6188 - val_accuracy: 0.1709\n",
      "Epoch 8/100\n",
      "307/307 [==============================] - 297s 968ms/step - loss: 2.4388 - accuracy: 0.1840 - val_loss: 2.5246 - val_accuracy: 0.1862\n",
      "Epoch 9/100\n",
      "307/307 [==============================] - 298s 971ms/step - loss: 2.3252 - accuracy: 0.2021 - val_loss: 2.5549 - val_accuracy: 0.1837\n",
      "Epoch 10/100\n",
      "307/307 [==============================] - 296s 964ms/step - loss: 2.2022 - accuracy: 0.2230 - val_loss: 2.4621 - val_accuracy: 0.2015\n",
      "Epoch 11/100\n",
      "307/307 [==============================] - 297s 967ms/step - loss: 2.1224 - accuracy: 0.2422 - val_loss: 2.3687 - val_accuracy: 0.2143\n",
      "Epoch 12/100\n",
      "307/307 [==============================] - 296s 966ms/step - loss: 2.0175 - accuracy: 0.2526 - val_loss: 2.4185 - val_accuracy: 0.2321\n",
      "Epoch 13/100\n",
      "307/307 [==============================] - 299s 973ms/step - loss: 1.9184 - accuracy: 0.2828 - val_loss: 2.5114 - val_accuracy: 0.2628\n",
      "Epoch 14/100\n",
      "307/307 [==============================] - 296s 966ms/step - loss: 1.8469 - accuracy: 0.2990 - val_loss: 2.3800 - val_accuracy: 0.2730\n",
      "Epoch 15/100\n",
      "307/307 [==============================] - 297s 968ms/step - loss: 1.7565 - accuracy: 0.3615 - val_loss: 2.3518 - val_accuracy: 0.2679\n",
      "Epoch 16/100\n",
      "307/307 [==============================] - 296s 965ms/step - loss: 1.6749 - accuracy: 0.3912 - val_loss: 2.4799 - val_accuracy: 0.2985\n",
      "Epoch 17/100\n",
      "307/307 [==============================] - 297s 966ms/step - loss: 1.5859 - accuracy: 0.4105 - val_loss: 2.4939 - val_accuracy: 0.2832\n",
      "Epoch 18/100\n",
      "307/307 [==============================] - 297s 968ms/step - loss: 1.4637 - accuracy: 0.4399 - val_loss: 2.2781 - val_accuracy: 0.2959\n",
      "Epoch 19/100\n",
      "307/307 [==============================] - 296s 964ms/step - loss: 1.4538 - accuracy: 0.4718 - val_loss: 2.3574 - val_accuracy: 0.3138\n",
      "Epoch 20/100\n",
      "307/307 [==============================] - 297s 967ms/step - loss: 1.3604 - accuracy: 0.4996 - val_loss: 2.4646 - val_accuracy: 0.3061\n",
      "Epoch 21/100\n",
      "307/307 [==============================] - 297s 968ms/step - loss: 1.2684 - accuracy: 0.5225 - val_loss: 2.4661 - val_accuracy: 0.3214\n",
      "Epoch 22/100\n",
      "307/307 [==============================] - 299s 975ms/step - loss: 1.1865 - accuracy: 0.5600 - val_loss: 2.6602 - val_accuracy: 0.3214\n",
      "Epoch 23/100\n",
      "307/307 [==============================] - 296s 963ms/step - loss: 1.1405 - accuracy: 0.5895 - val_loss: 2.8001 - val_accuracy: 0.3010\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "rgb_train_history = rgb_model.fit(\n",
    "    x=train_dataset, \n",
    "    validation_data=val_dataset, \n",
    "    epochs=100, \n",
    "    callbacks=[early_stop_callback, csv_callback, checkpoint], \n",
    "    workers=10, \n",
    "    use_multiprocessing=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "industrial-exemption",
   "metadata": {},
   "source": [
    "## EfficientNetB7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "union-technique",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, None, 224, 224, 3 0         \n",
      "_________________________________________________________________\n",
      "EfficientNetB7 (TimeDistribu (None, None, 7, 7, 1280)  4049571   \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, None, 1280)        0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 256)               1573888   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 20)                2580      \n",
      "=================================================================\n",
      "Total params: 5,658,935\n",
      "Trainable params: 1,609,364\n",
      "Non-trainable params: 4,049,571\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "rgb_model = single_feature_model(20, model_num=7)\n",
    "rgb_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "occupational-repeat",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_log = 'training_rgb_004.csv'\n",
    "run_model_summary = 'training_rgb_004_model_summary.txt'\n",
    "model_checkpoint = 'training_rgb_004.best.hdf5'\n",
    "\n",
    "with open(Path(OUTPUT_PATH, run_model_summary), 'w') as f:\n",
    "    rgb_model.summary(print_fn=lambda x: f.write(x + '\\n'))\n",
    "\n",
    "early_stop_callback = set_early_stop_callback(5)\n",
    "csv_callback = set_csv_callback(OUTPUT_PATH, run_log)\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath=Path(OUTPUT_PATH, model_checkpoint), \n",
    "                                                monitor='val_loss',\n",
    "                                                verbose=0,\n",
    "                                                save_best_only=True,\n",
    "                                                mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "normal-african",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "307/307 [==============================] - 312s 981ms/step - loss: 3.0273 - accuracy: 0.0694 - val_loss: 2.9340 - val_accuracy: 0.0816\n",
      "Epoch 2/100\n",
      "307/307 [==============================] - 296s 964ms/step - loss: 2.9353 - accuracy: 0.0721 - val_loss: 2.9268 - val_accuracy: 0.0791\n",
      "Epoch 3/100\n",
      "307/307 [==============================] - 297s 968ms/step - loss: 2.9195 - accuracy: 0.0788 - val_loss: 2.8691 - val_accuracy: 0.0918\n",
      "Epoch 4/100\n",
      "307/307 [==============================] - 299s 974ms/step - loss: 2.8653 - accuracy: 0.0977 - val_loss: 2.8018 - val_accuracy: 0.1020\n",
      "Epoch 5/100\n",
      "307/307 [==============================] - 295s 960ms/step - loss: 2.7413 - accuracy: 0.1293 - val_loss: 2.7500 - val_accuracy: 0.1276\n",
      "Epoch 6/100\n",
      "307/307 [==============================] - 295s 961ms/step - loss: 2.6290 - accuracy: 0.1377 - val_loss: 2.6529 - val_accuracy: 0.1531\n",
      "Epoch 7/100\n",
      "307/307 [==============================] - 295s 961ms/step - loss: 2.4785 - accuracy: 0.1809 - val_loss: 2.5101 - val_accuracy: 0.1709\n",
      "Epoch 8/100\n",
      "307/307 [==============================] - 295s 962ms/step - loss: 2.3282 - accuracy: 0.2156 - val_loss: 2.3534 - val_accuracy: 0.1913\n",
      "Epoch 9/100\n",
      "307/307 [==============================] - 295s 963ms/step - loss: 2.1557 - accuracy: 0.2415 - val_loss: 2.2832 - val_accuracy: 0.2321\n",
      "Epoch 10/100\n",
      "307/307 [==============================] - 296s 964ms/step - loss: 2.0508 - accuracy: 0.2809 - val_loss: 2.2419 - val_accuracy: 0.2296\n",
      "Epoch 11/100\n",
      "307/307 [==============================] - 296s 964ms/step - loss: 1.9428 - accuracy: 0.3044 - val_loss: 2.2151 - val_accuracy: 0.2347\n",
      "Epoch 12/100\n",
      "307/307 [==============================] - 296s 963ms/step - loss: 1.8093 - accuracy: 0.3303 - val_loss: 2.3328 - val_accuracy: 0.2679\n",
      "Epoch 13/100\n",
      "307/307 [==============================] - 297s 968ms/step - loss: 1.6826 - accuracy: 0.3604 - val_loss: 2.1873 - val_accuracy: 0.2628\n",
      "Epoch 14/100\n",
      "307/307 [==============================] - 297s 969ms/step - loss: 1.5854 - accuracy: 0.3899 - val_loss: 2.3657 - val_accuracy: 0.2857\n",
      "Epoch 15/100\n",
      "307/307 [==============================] - 296s 964ms/step - loss: 1.4967 - accuracy: 0.4476 - val_loss: 2.3093 - val_accuracy: 0.2883\n",
      "Epoch 16/100\n",
      "307/307 [==============================] - 298s 970ms/step - loss: 1.4099 - accuracy: 0.4695 - val_loss: 2.3110 - val_accuracy: 0.2908\n",
      "Epoch 17/100\n",
      "307/307 [==============================] - 296s 965ms/step - loss: 1.3783 - accuracy: 0.5032 - val_loss: 2.4445 - val_accuracy: 0.3495\n",
      "Epoch 18/100\n",
      "307/307 [==============================] - 296s 965ms/step - loss: 1.2448 - accuracy: 0.5356 - val_loss: 2.3609 - val_accuracy: 0.3342\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "rgb_train_history = rgb_model.fit(\n",
    "    x=train_dataset, \n",
    "    validation_data=val_dataset, \n",
    "    epochs=100, \n",
    "    callbacks=[early_stop_callback, csv_callback, checkpoint], \n",
    "    workers=10, \n",
    "    use_multiprocessing=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pleased-perfume",
   "metadata": {},
   "source": [
    "## Run more!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "hidden-brush",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_TRIALS = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "steady-blanket",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "    296/Unknown - 1278s 4s/step - loss: 3.0264 - accuracy: 0.0702"
     ]
    }
   ],
   "source": [
    "# B0\n",
    "TRIAL_START = 7\n",
    "for i in range(NUM_TRIALS):\n",
    "    trial_num = i + TRIAL_START\n",
    "    rgb_model = single_feature_model(20, model_num=0)\n",
    "    \n",
    "    run_log = f'training_rgb_{trial_num:03}.csv'\n",
    "    run_model_summary = f'training_rgb_{trial_num:03}_model_summary.txt'\n",
    "    model_checkpoint = f'training_rgb_{trial_num:03}.best.hdf5'\n",
    "\n",
    "    with open(Path(OUTPUT_PATH, run_model_summary), 'w') as f:\n",
    "        rgb_model.summary(print_fn=lambda x: f.write(x + '\\n'))\n",
    "\n",
    "    early_stop_callback = set_early_stop_callback(5)\n",
    "    csv_callback = set_csv_callback(OUTPUT_PATH, run_log)\n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath=Path(OUTPUT_PATH, model_checkpoint), \n",
    "                                                    monitor='val_loss',\n",
    "                                                    verbose=0,\n",
    "                                                    save_best_only=True,\n",
    "                                                    mode='min')\n",
    "    \n",
    "    # Train\n",
    "    rgb_train_history = rgb_model.fit(\n",
    "        x=train_dataset, \n",
    "        validation_data=val_dataset, \n",
    "        epochs=100, \n",
    "        callbacks=[early_stop_callback, csv_callback, checkpoint], \n",
    "        workers=10, \n",
    "        use_multiprocessing=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arctic-norway",
   "metadata": {},
   "outputs": [],
   "source": [
    "# B2\n",
    "TRIAL_START += NUM_TRIALS\n",
    "for i in range(NUM_TRIALS):\n",
    "    trial_num = i + TRIAL_START\n",
    "    rgb_model = single_feature_model(20, model_num=2)\n",
    "    \n",
    "    run_log = f'training_rgb_{trial_num:03}.csv'\n",
    "    run_model_summary = f'training_rgb_{trial_num:03}_model_summary.txt'\n",
    "    model_checkpoint = f'training_rgb_{trial_num:03}.best.hdf5'\n",
    "\n",
    "    with open(Path(OUTPUT_PATH, run_model_summary), 'w') as f:\n",
    "        rgb_model.summary(print_fn=lambda x: f.write(x + '\\n'))\n",
    "\n",
    "    early_stop_callback = set_early_stop_callback(5)\n",
    "    csv_callback = set_csv_callback(OUTPUT_PATH, run_log)\n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath=Path(OUTPUT_PATH, model_checkpoint), \n",
    "                                                    monitor='val_loss',\n",
    "                                                    verbose=0,\n",
    "                                                    save_best_only=True,\n",
    "                                                    mode='min')\n",
    "    \n",
    "    # Train\n",
    "    rgb_train_history = rgb_model.fit(\n",
    "        x=train_dataset, \n",
    "        validation_data=val_dataset, \n",
    "        epochs=100, \n",
    "        callbacks=[early_stop_callback, csv_callback, checkpoint], \n",
    "        workers=10, \n",
    "        use_multiprocessing=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excessive-tobago",
   "metadata": {},
   "outputs": [],
   "source": [
    "# B4\n",
    "TRIAL_START += NUM_TRIALS\n",
    "for i in range(NUM_TRIALS):\n",
    "    trial_num = i + TRIAL_START\n",
    "    rgb_model = single_feature_model(20, model_num=4)\n",
    "    \n",
    "    run_log = f'training_rgb_{trial_num:03}.csv'\n",
    "    run_model_summary = f'training_rgb_{trial_num:03}_model_summary.txt'\n",
    "    model_checkpoint = f'training_rgb_{trial_num:03}.best.hdf5'\n",
    "\n",
    "    with open(Path(OUTPUT_PATH, run_model_summary), 'w') as f:\n",
    "        rgb_model.summary(print_fn=lambda x: f.write(x + '\\n'))\n",
    "\n",
    "    early_stop_callback = set_early_stop_callback(5)\n",
    "    csv_callback = set_csv_callback(OUTPUT_PATH, run_log)\n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath=Path(OUTPUT_PATH, model_checkpoint), \n",
    "                                                    monitor='val_loss',\n",
    "                                                    verbose=0,\n",
    "                                                    save_best_only=True,\n",
    "                                                    mode='min')\n",
    "    \n",
    "    # Train\n",
    "    rgb_train_history = rgb_model.fit(\n",
    "        x=train_dataset, \n",
    "        validation_data=val_dataset, \n",
    "        epochs=100, \n",
    "        callbacks=[early_stop_callback, csv_callback, checkpoint], \n",
    "        workers=10, \n",
    "        use_multiprocessing=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modular-meaning",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# B7\n",
    "TRIAL_START += NUM_TRIALS\n",
    "for i in range(NUM_TRIALS):\n",
    "    trial_num = i + TRIAL_START\n",
    "    rgb_model = single_feature_model(20, model_num=7)\n",
    "    \n",
    "    run_log = f'training_rgb_{trial_num:03}.csv'\n",
    "    run_model_summary = f'training_rgb_{trial_num:03}_model_summary.txt'\n",
    "    model_checkpoint = f'training_rgb_{trial_num:03}.best.hdf5'\n",
    "\n",
    "    with open(Path(OUTPUT_PATH, run_model_summary), 'w') as f:\n",
    "        rgb_model.summary(print_fn=lambda x: f.write(x + '\\n'))\n",
    "\n",
    "    early_stop_callback = set_early_stop_callback(5)\n",
    "    csv_callback = set_csv_callback(OUTPUT_PATH, run_log)\n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath=Path(OUTPUT_PATH, model_checkpoint), \n",
    "                                                    monitor='val_loss',\n",
    "                                                    verbose=0,\n",
    "                                                    save_best_only=True,\n",
    "                                                    mode='min')\n",
    "    \n",
    "    # Train\n",
    "    rgb_train_history = rgb_model.fit(\n",
    "        x=train_dataset, \n",
    "        validation_data=val_dataset, \n",
    "        epochs=100, \n",
    "        callbacks=[early_stop_callback, csv_callback, checkpoint], \n",
    "        workers=10, \n",
    "        use_multiprocessing=True\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
